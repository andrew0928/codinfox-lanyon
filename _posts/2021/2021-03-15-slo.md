---
layout: post
title: "[架構師的修練] #2, SLO - 如何確保服務水準? "
categories:
- "系列文章: 架構師的修練"
tags: ["系列文章", "架構師的修練", "刻意練習"]
published: false
comments_disqus: false
comments_facebook: false
comments_gitalk: true
redirect_from:
logo: 
---

繼 [上一篇]() 講完整個我對技術人員職涯要持續成長，就必須要刻意的持續練習看法後，這篇我就來舉實際的案例吧。你累積的經驗或是能力，若無法轉換為價值，那是沒有用的。技術人能展現的價值，就是解決問題。怎樣才能讓一個問題拿到你面前你都能迎刃而解? 最有用的就是連結你累積的各種能力。連結越強，織起來的知識網就越強韌，你看問題就會越到位。

這篇我就拿我在去年 91APP TechDay 以及 .NET Conf 2020 Taipei 分享的主題: 維持非同步系統的 SLO 來當例子吧。這是近年來我擔任架構師，端出來的幾個 solution 之中，對於 "連結" 這件事最有代表性的案例了。要解決這問題，你不但要有很札實的技術及實作能力、也要有很到位的 cloud infrastructure 掌控能力，同時還要具備管理知識，缺一不可，才有可能把這件事情解的漂亮。表面上看來，訂定服務水準要達成的目標 (SLO, Service Level Objective) 並落實，是個很純粹的技術題目啊，但是真正做過的人就知道，只靠技術能力硬拚，總是缺了點什麼，沒有辦法做到盡善盡美。我自己的心得是，越複雜的問題 (即使是系統問題)，你越需要從管理的角度去思考怎麼解決他 (當然最後還是要寫成 code)。

<!--more-->

往下的探討，我都會圍繞著這主題: 非同步系統的服務水準保證。這邊所謂的 "非同步系統"，你就想像成是我們內部開發的類似 FaaS (Function As A Service) 的服務，各個產品線都有一些需要非同步執行的任務 (Task), 往我們的這套系統丟；我們這套系統就要想辦法盡快安排資源，來將這些任務喚醒執行。這些任務每天都有上百萬個等著被執行，任務規模有大有小 (從 0.1 sec 執行完畢，到 1 小時都有)；每個都期待要 ASAP, 偏偏這些任務又不完全是同一個團隊開發的，於是就開始有各種矛盾出現... 別人寫的 code 卻要我們來確保他會在保證的時間內執行完畢。

如果你也覺得這事件不可能的任務，那恭喜你，你已經開始可以理解這個問題的困難點了。請繼續看下去 XDD


# 前言: 確認要解決的問題是什麼?

雖然這篇是把我演講的內容寫成文章，但是演講有時間限制，可能大家沒耐性聽我講一堆故事...。不過這是我的部落格，我想寫一些我想寫的...。我想要把演講當下沒辦法交代清楚的脈絡一起寫出來交代清楚，這樣才能前後連貫的說明我思考的脈絡。前面這段 [前言]，算是問題的背景，我花點時間交代一下...

前面講過 FaaS, 我相信用過 Azure Functions, 或是 AWS Lambda 等服務，大概都能想像吧。我們期待讓 developer 能無腦的只管把任務 create 建立起來往後端丟，之後就等著執行完畢拿結果回來就好。好處很多，最主要的是不必阻塞 (block) 前端的回應，間接的也節省很多不必要的等待跟鎖死資源。透過 message queue 來管理這些任務，就能提高可靠度，同時我們也能更容易的調節後端的運算資源，提高使用率。在雲端的世界裡，提高使用率就代表你能用更少的 instance 做同樣的事情，成本自然就會降低。

不過所有事情都有正反兩面啊! 我隨便舉就有一堆:

1. 使用率越高，代表空閒的機器越少，越難應付突發的需求；一旦發生瞬間流量，可能會導致部分任務需要等待更多時間才能得到執行結果。  
> 拉高使用率的前提，在於你需要有很快速靈活的調度能力 (例如開新機器的速度、將 task 轉移到新機器的速度) 來搭配。
1. 承 (1), 多準備一些運算資源 (多開機器) 在旁邊待命當然可以解決，但是這樣也讓成本上升。
1. 每個任務的特性都不同，有的一瞬間結束，有的一跑就是幾分鐘；有的吃 CPU，有的吃 IO，有的吃 Memory ..., 擺在一起容易互相干擾，分開擺使用率就難以拉高。
1. 有些任務需要保證時間內執行，有些不需要。混再一起會加大管理與監控負擔，同樣的分開則難以拉高使用率
...

相信有設計過大型的系統，對於這些矛盾都很熟悉吧? 我就點到為止，直接進入今天的主題。如果我的任務都有定義服務水準的期待 (SLO)，我該怎麼達成它? 系統的規模越大，分工就越細，單一任務可能涵蓋的團隊也有好幾個，當我的 task 無法在期待的時間內執行完畢，原因太多了，有可能 task 寫的太爛 (需要 optimize), 也有可能排程的系統 (orchestration) 寫的太爛, 也有可能是機器開的太少或是等級太低, 也有可能是客戶上傳了太多資料, 也有可能是網站的使用者太多, 或是突然面臨 DDOS 攻擊...

問題想到這邊，我開始意會到，光是把 code 按照規格寫好，把效能調教好是不夠的 (即使這件事我做到 100 分也一樣)。我必須多做點什麼，搭配額外的手段 (不管是技術還是非技術手段) 才有可能。所以我才聯想到過去的一些管理技巧，並且思考將他們應用在系統上...。



# 主題: 非同步系統的服務水準保證

以下我就直接用文字還原我在 session 上面說明的內容，在 session 當下我沒提到的內容我會另外註明。
如果你懶得看這些文字，想看現場的，我整理了當時的錄影以及投影片下載的連結，有需要的請直接取用:

* 錄影
* 投影片下載

![](/wp-content/images/2021-03-15-slo/slides/投影片2.png)

其實我每次固定參加的幾場研討會，我發表的內容都是有延續的。例如 .NET Conf, 或是 DevOpsDays Taipei 我都默默地維持這個慣例。一開始我回顧了過去幾年我在 .NET Conf 發表的主題 (我竟然也參加了四年了... Orz)


![](/wp-content/images/2021-03-15-slo/slides/投影片4.png)
2017, 我分享的主題是: 容器驅動開發, Container Driven Development
說明的是如果容器化部署已經是你團隊中的標準做法了，那麼這樣的基礎建設能替你的開發方式做那些簡化跟改善?



![](/wp-content/images/2021-03-15-slo/slides/投影片5.png)
2018, 我分享的主題是: Message Queue Based RPC
透過 message queue 來做非同步的通訊 (單向) 已經是很成熟的技術了，我們也開始拿它做為分散式非同步任務處理的基礎。使用的地方越多，各種需求就越多，其中一種最常碰到的就是: 如果我想要取得非同步任務的結果該怎麼辦? 雖說是非同步，但是我也期待能夠用同步的方式得到執行結果，那該如何處理?

這個 session 就是說明如何善用 C# 的 async / await 機制，搭配雙向的 message queue 通訊，搭建以 message queue 為基礎的 RPC (Remote Procedure Call) 的設計。你可以同時兼顧 message queue 帶來的可靠度與高效率, 也可以藉由 C# 的 async / await 帶來接近 real time 的便利性。


![](/wp-content/images/2021-03-15-slo/slides/投影片6.png)
2019, 這次玩的比較大，我開始嘗試在同一場研討會分享較大規模的主題，因此跟主辦單位要了連續兩個 session 的時間來分享。主題是:
- 大規模微服務導入 #1, 從零開始的系統架構設計概觀
- 大規模微服務導入 #2, 從零開始的微服務 .NET Core 框架設計

這兩場我說明了大型團隊怎麼在 code / infra / config 三個層面的部署與管理取得一個平衡的作法。通常這是三類型專長的人員在負責的 (開發 / 維運 / 營運)。沒有事先把三者的協作方式定義好，規模一大很容易出問題的。上半場就在講這些設計的概念，下半場則是基於這個概念，那麼開發團隊應該要建立起甚麼樣的基礎框架才能辦的到?

這兩場我覺得很可惜，要講的東西有點龐大，但是我的表達能力還不夠到位，足以在 100 分鐘內交代完這些想法，最後當然是超時啦，也被迫省略了一些細節。同樣的，這些內容都公開，有機會我再看看有沒有空也把它寫成文章...


![](/wp-content/images/2021-03-15-slo/slides/投影片8.png)
回到 2020, 這次我們直接要了一整軌，用四個主題串起我們想分享的內容。按照順序:
- Ruddy 老師:     DevOps 教戰手冊 - 三步工作法
- Andrew:        (就是這篇) 非同步系統的服務水準保證
- Steven Tsai:   微型任務編排器 - Process Pool
- Andrew / Fion: (這應該會是下一篇) 刻意練習 - 如何鍛鍊你的抽象化能力

其實這些內容也是我刻意安排的。由 Ruddy 老師多年的 DevOps 心法來開場，講了很多靠經驗累積下來的實作心得。而我這場就是實際推行的案例，就是前面提到的非同步系統怎樣達成 SLO 的期待。而非同步的系統，背後就是靠 2017 / 2018 分享的技術搭建起來的啊! 擴大到全團隊使用，靠的就是 2019 那場分享的框架來搭建的。而要維持資源的高使用率，靠的就是第三場提到的 Process Pool。這一連串的機制，都對團隊的實作能力有很高的要求才辦的到。因此第四場講的刻意練習，就是說明平日該如何鍛鍊才能累積這樣的實作能力。

其實這幾頁投影片，我在當日的 session 只用了一兩分鐘就帶過了 (沒辦法，時間真的有限)。我偏愛寫文章也是這樣，比較沒有篇幅或是時間的限制，內容也容易連結，比較能夠有系統地把這些分享的內容組織起來。如果你是我部落格的忠實讀者，我相信這些主題過去你都看過了。我也累積了夠多的內容，開始可以一個一個串連起來應用了。講到這邊，我就拿這開場來呼應上一篇講的 "連結"，這就是我實際串聯的案例。

既然底層的實作 (Container, Message Queue RPC, Process Pool) 都有另外的篇幅來說明了，我這篇就繼續往我的主題: 服務水準保證 來推進吧!



# 1, 何謂服務水準? 該如何量化與量測?

我習慣在深入各種細節之前，先把主軸或是定義講清楚。既然講到 "服務水準" 這件事，就不能忽略 SLA / SLO(s) / SLI(s) 是什麼。開始之前，我先講一小段案例。我們團隊很擅長大型服務的維運，這背後是有套流程的，為了凸顯我們跟一般的開發團隊的差異 (尤其是開發外包、或是各種系統整合外包商)，我拿這張 slide 來說明:

![](/wp-content/images/2021-03-15-slo/slides/投影片19.png)

大部分的人，想到大流量，不外乎就是水平擴展 (scale out) 之類很直接的面對流量。實際上這些都是要花錢的，比起力大無窮，實際的狀況更追求精準的力道。要水平擴展前，你必須先知道現在 "該不該" 擴展，也就是必須先做到監控。

既然要監控，就要有明確的監控標的。我們的作法是，先挑選你期待的服務水準。這張投影片上說的是 99% 的 request 都必須在 300ms 內完成回應 (response)... 這就是我們期待的服務水準 "目標"，也就是所謂的 SLO ( Service Level Objective )。當然你可以定義多個 SLO，不過我們就拿最重要的回應時間當代表就好。

SLO 定義好之後，維運團隊必須按照這個指標 (每一瞬間 99% 的 request, 最高的 response time) 來進行監控。把 SLO 的 O 拆掉後，就只剩單純的指標定義，這個指標就是所謂的 SLI ( Service Level Indicator )。監控的團隊，必須想辦法在系統埋下各種探針 ( probe ), 收集完整的數據, 以便讓維運團隊隨時能掌控 SLI 的狀況。為了加速處理速度，通常也會替 SLI 做分級，與其回報一堆數字，另一種做法是分級用燈號來標示，維運團隊只要看燈號的顏色就能立刻了解目前服務的水準是否需要留意。以前面提到 SLI 必須低於 300ms 的期待，監控團隊可以這樣設置:

- 當指標低於 150ms, 該指標的燈號為綠燈 (安全)
- 當指標介於 150ms ~ 200ms 之間, 該指標燈號為黃燈 (需要留意)
- 當指標高於 200ms, 該指標燈號為紅燈 (發送警告通知，需要立即處理)

維運團隊的值班人員，按照這個流程，理論上都能在第一時間讓系統回復正常的服務水準。不過指標會亮黃燈或紅燈，可能是個案，也可能是個趨勢。同時對服務水準的期待 (SLO)，也有可能因為市場或是使用者的變化而有所改變。這時維運團隊應該定期檢討指標是否合理? 例如是否該將 300ms 的要求調低? 或是檢討過去一個月進入黃色燈號的比例已經提高，系統本身應該有其他狀況需要額外處置 (效能優化，或是擴充運算能力等等)。

這整個流程，就是一個基礎的 DevOps 循環，藉由監控的回饋，給開發團隊更明確的優化或是調教的指示。改善後回到前線，評估是否有改善，然後再取得回饋。如此不斷的循環，系統就會不斷的進化。



了解這些過程後，回頭來看看這三個名詞的定義，應該就很清楚了。我擷取網路上的定義:

![](/wp-content/images/2021-03-15-slo/slides/投影片19.png)

最後補上前面沒提到的 SLA ( Service LEvel Agreement )。維運團隊內部，工程單位看的是 SLO / SLI, 而 SLA 則是跟使用者達成的協議 (Agreement) 或是合約。意思是當服務未達預期目標 (SLO) 時，服務方應該要做的處置，以及事後的賠償條款等等。


# 2, Case Study: 驗證簡訊的發送

講一堆文字敘述很難想像，我就直接舉一個內部實際的處理案例吧。有些內部資訊不方便直接公開，因此相關的數據或是描述，我都稍作調整，以下的數據不代表實際的情況。各位應該都碰過這種情況吧? 在一個網站上註冊帳號，為了確定你資料沒有亂填 (例如: 電話號碼)，因此在註冊當下，會用簡訊 (SMS) 發送一個 4 ~ 6 位數的驗證碼，到你填寫的手機號碼裡。

驗證碼背後通常都有這幾個特性需要滿足:

1. 使用者通常在前端等待，因此驗證碼必須在依定的時間內發送出去 ( ex: 5 sec )
1. 為了避免使用者用暴力法闖關，驗證碼都有一段時效限制，你必須在這時間內輸入才有效 ( ex: 5 sec)

由於發送簡訊，是一連串呼叫內部與外部系統的過程，為了不影響前台的效能，一般都會用非同步的方式處理。因此我們也用了很典型的架構設計來處理這問題。我簡化過後，這是當時我們第一版的系統架構:

![](/wp-content/images/2021-03-15-slo/slides/投影片22.png)

從工程角度，我們很容易地把 "同一種功能" 集中起來重複使用，這很自然，不是嗎? 於是，當驗證簡訊開發完成後，另一個團隊需要發送行銷簡訊，當然就共用同一套 code 了。於是系統就長成上圖的樣子。這時，當碰到周年慶或是大型活動時，瞬間有大量的行銷簡訊發送，於是 message queue 就開始堆積了... 雖然系統不至於垮掉 ( message queue 能夠調節負載，後級可以用最有效率的節奏，穩定的持續運行 )，但是... 驗證簡訊被迫開始要跟著一起排隊，有些簡訊無法在 5 sec 內被發送出去...

(上圖的綠色，代表驗證簡訊)

回想前面的流程。我知道每個工程師都急著想解決方法 (例如 scale out 後端的 worker ... )。不過，別急著動手，先想一下如果這種情況發生了，你該如何才能精準的知道: 現在驗證簡訊邀花多少時間才能發送成功?

比起怎麼改善，你先掌握正確的 SLI 還來的更重要。你如果直接告訴 infra 團隊，要他在監控系統拉一個 "簡訊發送時間" 的指標給你，他一定跟你翻白眼。沒有任何一個監控系統裝好後就有這指標可以用啊，這完全是 business domain 裡才有的資訊，你必須自己從系統裡面抓出來才行。因此，我繼續把上面那張圖拿出來，把我們期待的指標拆解，拆成幾個系統實際上能監控的更細緻的指標，直到我們能監控為止。

![](/wp-content/images/2021-03-15-slo/slides/投影片23.png)

這邊，我就忽略掉簡訊商跟電信商之間的通訊時間了，我定義成 5 sec 內一定要把簡訊成功地送到第三方服務那端。我把這段時間拆成三段:

- A (準備時間):
- B (等待時間):
- C1 (內部執行時間):

發送簡訊的要求，在我們系統內部就拆成這三段，因此我只要能夠監控這三個數據，加起來別超過 5 sec 就是了。因此，開發團隊開始接到新任務，必須按照監控系統提供的 metrics collect API 的定義，把這三個指標送進去。監控人員必須設定警告條件，當 A + B + C1 > 5 sec 時就該發送警告通知。




發現問題後，團隊再來逐一檢測，那就太慢了。所以通常我們會事先擬定好診斷狀況的 SOP，方便值班人員能夠更快的判定數據，做出正確的處置。因此，對於驗證簡訊的處理，我們列了第一份緊急處置標準程序:

![](/wp-content/images/2021-03-15-slo/slides/投影片25.png)

當然，每個數值多少算高，多少算低，都有定義，我這邊就省略這些細節，只講重點就好。團隊按照 SOP 做了處置，判定 (B) 的數值過高。不過 (B) 過高還可能有兩種狀況，一種是真的訊息發送量太大，所以堆積太多排隊排太久... 另一種是訊息量正常，但是後端處理很慢都有可能。為了進一步區分這兩種狀況，我們引入了第四個指標: 

- D (排隊的長度, Queue Length):

如果 (B) 偏高，(D) 也偏高，就是訊息量太多，高於平日正常的量
如果 (B) 偏高，(D) 正常，那代表是處理效能過慢的原因

透過這樣的對照表，就很容易讓第一線的人員很快判定狀況，做好處置的決策。回到前面行銷簡訊造成阻塞的 case, 應該就是 (B) 跟 (D) 都偏高的 case, 因此團隊很自然地想: 要加速消化訊息，我就把後端的 worker 多開幾個吧!



的確，這樣做很有效果，的確發送延遲的狀況減緩了。不過在定期檢討的時候回過頭來看看，這真的是理想的解決方案嗎?




