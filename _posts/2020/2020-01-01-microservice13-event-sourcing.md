---
layout: post
title: "微服務架構設計 - Event Sourcing"
categories:
- "系列文章: .NET + Windows Container, 微服務架構設計"
- "系列文章: 架構師觀點"
tags: ["microservice", "系列文章", "架構師", ]
published: false
comments: true
redirect_from:
logo: 
---


好久沒寫微服務系列的文章了，前陣子有個專案的關係，開始認真的評估 "Event Sourcing" 的設計方式，就順手寫篇心得來記錄一下。這次不寫那麼長了 (希望啦)，我想記錄一下到底甚麼場景下，你才真的需要使用到 Event Sourcing 的設計架構...。




# 簡介: 什麼是 Event Sourcing ?

其實 Event Sourcing 不算是新架構或是新觀念，早在 2000+ 的時候就很多人在討論了；我找了篇大神寫的文章: Martin Fowler - pEvent Sourcing](https://martinfowler.com/eaaDev/EventSourcing.html) 來當作代表就好了。所謂的 Event Sourcing, 其實背後的理念就是:

> 要儲存的，不是最後的資料，而是記錄讓資料改變的資訊歷程；如果你能完整記錄這些歷程，你就有能力還原任何時間點的資料狀態。

從定義上來說，如果你的 input 是以 "異動" 的過程為主，那麼你的紀錄就變成 log 型態的流水帳了。先不講優缺點，這樣做有幾個系統層面的特性:

1. 紀錄只會增加，你不能也不應該異動這些歷史資料。因此資料處理的模式從一般的 CRUD，簡化為 CR 而已。D 變成有限度的操作 (例如 archive) 而已。
1. 配合記錄流水帳的需要，前端處理通常會搭配 CQRS，強迫資料的異動進入資料庫前就被序列化
1. Event Sourcing 會帶來一些好處，但是不利於頻繁的計算最終結果的操作。通常架構上需要搭配 CQRS 同步更新 aggration view






講的白話一點，你拿出你的存摺出來看看就知道了。存摺清楚的按照時間序，把你每一筆款項的進出都記錄下來，何時存款，何時提款等等；每一筆異動紀錄，最後面才會附上當下結算的帳戶餘額。

然而，存摺是一筆一筆的印在本子上的啊，印出來的紀錄就不會被消掉了，紀錄只會不斷的往後面附加上去。想像一下，銀行能在本子上打出這些資料，他背後一定是這樣紀錄資料的。這樣的好處顯而易見:

1. 紀錄資料異動的順序，可以完整保存異動的過程 (而非只是記錄結果)
1. 有需要時你能有足夠的資訊重新還原過程
1. 來源資料只會 "新增"，不會更新也不會刪除。適合交易相關的資料處理 (要保留流水帳)

...

這樣做有什麼好處? 如果你在設計銀行的系統，試著想像一下下列情境:

> 如果交易過程中，有帳務弄錯了 (例如算錯利息)，我有能力修正後重新計算最終的結果, 然後追加一筆補差額的紀錄嗎? 

這邊的對照組是: 我只替每個帳戶紀錄最後的餘額，每次有資金異動，我就會用 update 的方式更新餘額 (當然我為了保險起見也會寫下 log)。但是，log 跟 event sourcing 的 event 紀錄最大的不同是, event 本來就是來源資料, 我可以拿來重新計算；log 則只能拿來查閱, 我很難再匯回系統按照 log 重新計算一次啊...

很顯然的，這些好處，都建立在完整的 event 紀錄上，缺點也是顯而易見的，我必須耗費大量的 storage 跟運算能力才能支撐這樣的設計... (至於 developer 的技能要求門檻就更高了，這部分我就不討論)，沒有必要的話這也不見得是個好設計。


好，先做點功課，先了解 "event sourcing" 到底是指啥, 入門介紹先到此為止，其他觀念後面再探討。


# 雲端時代的架構設計觀念 - cloud native

"Cloud" 這名詞，喊了十幾年了，到現在已經不算是啥新技術了，而是到處都看的到的應用了。不過很多開發人員，開發跟架構的思維還是沒有轉移到 "cloud" 啊! 我在繼續這主題前，我先亂入這段...

引用我半年前在 facebook 貼的一段[評論](https://www.facebook.com/andrew.blog.0928/posts/848315655543714):


```

這篇文章還不錯，介紹了 google 技術發展的過程。這勾起了我當年 (2008 剛開始在談雲端的時候) 看到 google 如何走出不一樣的路時的震撼...

更早 2000 年的時候，企業的 IT 當道，主流都還是 windows server 的年代。當時 server 都是靠更高級的設備堆出可靠度的, 舉例來說: 如果一顆硬碟的故障率是 1% 的話，用 RAID1 就可以把故障率降低到 0.01% ..., 這已經是 99.99% 的 SLA 了，而且你有機會在服務掛掉前替換故障的硬體... 所以程式開發人員就可以有個可靠的平台，不需要傷腦筋可靠度這件事，只要有可靠的 IT 幫你照顧好 server ...

但是這個前提在雲端 (planet scale) 的年代就被打破了。再高級的硬體, 如果乘上極大的數量 (例如: 10000 台 server)，那麼這個故障率就又被放大到不可忽視了。

Google 當年其中一個核心觀念就是: 在某個規模之上，硬體的故障就是不可避免的。與其在硬體上不斷靠備援來拉高可靠度，不如在軟體服務的設計上，本身就允許設備的故障...

因為這個觀念，才發展出 BigTable 這類儲存方式，一份資料存放三份，故障了就整個節點直接離線，重新建立損失的那一份資料。整個 cluster 就像有機體一樣可以自行適應不完美的環境...

另一個重要的變革就是 MapReduce (我是看不懂複雜的論文跟演算法啦)，同樣背後有很基本的觀念改變: 資料量大到某個規模以上的時候 (例如: PB 級以上)，傳統資料庫的架構就不適用了。資料庫都是以 "運算" 為中心的，強大的 server 有足夠的 CPU / RAM 等運算資源，搭配有高可用性的 storage, 組成效能強大的資料庫。不過先天的限制是，這架構都是把 "資料" 送到 "運算資源" 端才進行運算的... 效能瓶頸都卡在 I/O, 試想你要查詢的資料遍及 1PB (散在 1000 顆 1TB HDD), 你要多久才能夠掃完所有的資料?

與其把 Query 交給少數幾台 Server, 然後負責查詢的 Server 才想辦法把資料從 1000 HDD 拉回來查詢，MapReduce 則是完全反轉這個觀念，反過來以 "資料" 為中心，將 "運算(Query, 大概就是一小段 code)" 送到資料端就地的 Server (每台 server 可能只掛幾顆硬碟) 進行運算，然後再把運算結果集中起來。就地的運算就能避開跨網路大量的傳遞資料，反過來是本機查完資料後再透過網路收集結果。MapReduce 不但有效避開大量的 I/O 瓶頸，同時也大幅提高了 scalability, 能用極大的規模處理平行運算。

要支撐這樣動態且快速變化的系統, deployment, containerize, immultable server, health check, service discovery, service registry 等等機制都變成是必要的, 這些一路演變至今, 成就了目前 cloud native 的重要基礎。也難怪 Google 早期就有這樣的發展經驗, 融合這些開發與管理經驗的 K8S 才會那麼快的席捲整個 container orchestration 的市場..

蠻有意思的改變，當年搞懂了 Google 這些改變，加上念書時分散式系統有打好基礎，進入雲端服務的時代後，有這些基礎都能很快的就理解許多新架構葫蘆裡是在賣甚麼藥.. 觀念搞懂後剩下的實作就容易了。熟悉仍然要花不少功夫，但是觀念通了之後，熟悉工具花費的時間是線性的，搞懂觀念要花費的時間則很難預料..

講了一大堆，難得看到文章會講這種發展故事的，有興趣的話可以花點時間看一看 

```

[谷歌在微服务上的坑和教训](https://www.infoq.cn/article/L*bT1UfuVoj1I6NRNM3U)

我在這邊，特地提到 "cloud native" 的原因，主要就是我上面評論講的，很多時候，我們講的 cloud, microservices, big data... 等等, 不單純只是指 "流量很大"，或是 "交易量很大" 這類指標的差異而已；更大的差異是，本質上計算的架構已經完全不同了，所以你會需要有完全不同的架構設計方式。然而微服務背後的設計理念, 完全就是 cloud native 那一套, 只不過 microservices 更強調的是服務的切割方式與切割的邊界。在我看來是同一件事的一體兩面，後面我就都用 cloud native 當作代表了。

舉例來說，我在 2000 年那個年代，工作上大都是三層式架構 (有的還只有兩層)，一組 WEB，一組 AP，一組 DB 就搞定了，哪有甚麼分散式的觀念? 不過到了 Google 的規模，數量及改變了，很多觀念不再適用，才開始有了 "cloud native" 的轉變啊! 上面提到的都是各種例子，我認為這篇講到的 event sourcing 也是其中一例。

與其說 "event sourcing" 是要解決瞬間巨量，處理巨量資料，提高可靠度.. blah blah 等等，我都覺得那些只是最終的結果，你如果有這些目的，其實你會有更多直接有效的技巧，同樣能滿足目的。真正需要認真思考 event sourcing 這技術，我認為這本質上是純架構的選擇, 為了同時保存原始 event 的紀錄，同時用 streaming processing 的方式, 在收到資料的當下就處理好資料, 直接用你將來想查詢的方式預先處理好後存下來的作法, 歸納出來的架構模式, 就是 event sourcing。

真的要看細節，這篇說的很到位:

[深入浅出Event Sourcing和CQRS](https://zhuanlan.zhihu.com/p/38968012)


我再把話題拉回 cloud native 這件事身上。當你運算規模大到某個程度, 你就應該採取不同的處理策略了。跨過那個數量及, 你所要採用的整套架構, 就應該改以 cloud native 為主了。我不直接談論 event sourcing, 我談他被後的處理方式。關連式資料庫，強調正規化，同樣的資料盡可能的正規化，不要放兩分，需要在靠關聯重新 join 回來，你就可以做到一致性。然而 cloud native 的處理策略則反過來, 收到資料當下, 就做好必要的處理，包括複寫到所有你要擺的地方，預先做好你要的處理；資料的正確性不靠交易與鎖定，而是靠可靠的通訊 (例如 message queue) 來將資料序列化與確保會被執行, 犧牲強一致性，換取最終一致性。

最大的差別，就是你能乘載的規模。這邊指的規模，不一定都是指淘寶雙十一那種瞬間巨量, 而是指你的架構能限性擴充的上限。指的不一定式線上的交易量，也可能是指你能夠處理的資料上限。舉例來說，採舉 join 的方式，在需要時才還原成你要的樣子，某種程度都會受資料總筆數的影響。相關的時間複雜度，取決於你的索引與你的查詢下的好壞。我就拿 O(log n) 當範例好了。但是如果用 cloud native 的思維去設計, 收到一筆資料就處理, 對於 DB 的操作都是用 key 去取得對應的 value, 時間複雜度通常會是 O(1), 而你要取得處理後的資料通常也是 O(1)... 很明顯的, 單筆資料不見得快, 也不見得能真的做到強一致性, 但是對於你能處理的規模上限, 或是線性擴充的能力, 則 cloud native 這派的哲學則是遠遠領先。

所以回到 event sourcing, 我會認為這只是 cloud native 整體思維下的一個常用的 pattern 而以；你通常不會 "單獨" 的使用 event sourcing 來解決問題。後面我就舉個我前陣子專案上碰到的例子，來說明一下我的想法。


# Event Sourcing 應用案例

我先把幾個名詞列一下，如果有你不懂的可以先預習一下。看懂後再往下看才不會一頭霧水。幾個必要的知識:

1. Message Queue
1. Streaming Data Processing
1. CQRS (Command / Query Responsibility Segregation)
1. DDD (Domain Driven Development)
1. No SQL (key value store)

原諒我工作上的案例，不能描述的太精確，我就舉一個典型的應用，套上我專案處理的架構來說明吧! 這樣大家可以同時了解概念，我也不需要過度暴露專案的細節。我就繼續沿用上述銀行存摺的例子好了。首先，核心業務一定是你的帳戶管理。來看看這段的設計:






















